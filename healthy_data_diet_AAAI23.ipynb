{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8266a43fc5f40d5a66b6d8b3c6f8a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a28f816d75314f8da27a4ea5d6758fc1",
              "IPY_MODEL_9e1885f058b242a5a6b299b08fb1e3e8",
              "IPY_MODEL_c8897b6ea00849a5ac3c549a0b383a09"
            ],
            "layout": "IPY_MODEL_fb47fba6e7ac40c4ae065297d1b5977c"
          }
        },
        "a28f816d75314f8da27a4ea5d6758fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1e326bbc4343b6bfc6a3304773804a",
            "placeholder": "​",
            "style": "IPY_MODEL_f7351f517ab84832ab1d12930f53624a",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "9e1885f058b242a5a6b299b08fb1e3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bb6bc86e3ee4f37a10dcec75f128bb9",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf8d4182250b4f499e03f03c4f3817a6",
            "value": 570
          }
        },
        "c8897b6ea00849a5ac3c549a0b383a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_340e8f67512a4133a3aa22d6257b86e7",
            "placeholder": "​",
            "style": "IPY_MODEL_bff1f78a9f9a491389c8438ede5f497d",
            "value": " 570/570 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "fb47fba6e7ac40c4ae065297d1b5977c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1e326bbc4343b6bfc6a3304773804a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7351f517ab84832ab1d12930f53624a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bb6bc86e3ee4f37a10dcec75f128bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf8d4182250b4f499e03f03c4f3817a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "340e8f67512a4133a3aa22d6257b86e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff1f78a9f9a491389c8438ede5f497d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18e695ff42c7497a90e78b7838c50d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_082e2b3139f1463bb35c922a899195b9",
              "IPY_MODEL_b03362380e0c4ad995fe34a51a589659",
              "IPY_MODEL_51e36ec24a914401bf5d43526961d15f"
            ],
            "layout": "IPY_MODEL_386a6cd59867470087bceef69c8fe462"
          }
        },
        "082e2b3139f1463bb35c922a899195b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd50f4c392e4415c9229c8d25912ef83",
            "placeholder": "​",
            "style": "IPY_MODEL_a95aca8e202548c68f143fbcffeb0773",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "b03362380e0c4ad995fe34a51a589659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ae61fe79414bcc85208e6c8f774b37",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cdd03d26f5d41eea1a6782ba43c88b4",
            "value": 435779157
          }
        },
        "51e36ec24a914401bf5d43526961d15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_167e784283c84439af85429c65842993",
            "placeholder": "​",
            "style": "IPY_MODEL_e90bb6b0168a497d82c8260eecc7bf5d",
            "value": " 436M/436M [00:10&lt;00:00, 45.6MB/s]"
          }
        },
        "386a6cd59867470087bceef69c8fe462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd50f4c392e4415c9229c8d25912ef83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a95aca8e202548c68f143fbcffeb0773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27ae61fe79414bcc85208e6c8f774b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cdd03d26f5d41eea1a6782ba43c88b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "167e784283c84439af85429c65842993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e90bb6b0168a497d82c8260eecc7bf5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3eb3cad001484041a03e22a026d2b912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e9387e72b07486f938a52e901de5463",
              "IPY_MODEL_46f27664935c4ae99fce551356054b81",
              "IPY_MODEL_19d733bc625f4761b0dc336d5e5356e4"
            ],
            "layout": "IPY_MODEL_72d5ee53c6c94e00afeb3c9ef634c022"
          }
        },
        "3e9387e72b07486f938a52e901de5463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f88571f31d84ba8a12b047c9f0cf77c",
            "placeholder": "​",
            "style": "IPY_MODEL_b20e66ef00814c8eb87afc5a0558f005",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "46f27664935c4ae99fce551356054b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdbd3ab62ab34075bb616d191b139b09",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80affc73986b4d6697a0a261ce8e58e1",
            "value": 481
          }
        },
        "19d733bc625f4761b0dc336d5e5356e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24173ede048848a5b5e79986516b27fa",
            "placeholder": "​",
            "style": "IPY_MODEL_1c66105e9fb4489f8858c3f9ac3c530d",
            "value": " 481/481 [00:00&lt;00:00, 19.3kB/s]"
          }
        },
        "72d5ee53c6c94e00afeb3c9ef634c022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f88571f31d84ba8a12b047c9f0cf77c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b20e66ef00814c8eb87afc5a0558f005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdbd3ab62ab34075bb616d191b139b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80affc73986b4d6697a0a261ce8e58e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24173ede048848a5b5e79986516b27fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c66105e9fb4489f8858c3f9ac3c530d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d290183ab127487184ab46dba813634a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d82f65b5ad0b458ea3cf02b97086faaf",
              "IPY_MODEL_0a5d163aae51484ea21c670082cd51a5",
              "IPY_MODEL_a53d08c9bcd8418ea90158c373a04f4e"
            ],
            "layout": "IPY_MODEL_66589e6f40b04c10a4cfee21f98a1f97"
          }
        },
        "d82f65b5ad0b458ea3cf02b97086faaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_573b251324364adbbfc9b6faf915b177",
            "placeholder": "​",
            "style": "IPY_MODEL_36ecc61017eb40a59dce0e7b8d74410e",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "0a5d163aae51484ea21c670082cd51a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d79317411914ecb967ac5427a6ebe5c",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d8eae7892ae47be972b9497d4d23cc8",
            "value": 501200538
          }
        },
        "a53d08c9bcd8418ea90158c373a04f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc0ab496e73463db6fac68b26b24832",
            "placeholder": "​",
            "style": "IPY_MODEL_c91687ff80064ddf89abd709fe398488",
            "value": " 501M/501M [00:10&lt;00:00, 49.8MB/s]"
          }
        },
        "66589e6f40b04c10a4cfee21f98a1f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "573b251324364adbbfc9b6faf915b177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36ecc61017eb40a59dce0e7b8d74410e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d79317411914ecb967ac5427a6ebe5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d8eae7892ae47be972b9497d4d23cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cc0ab496e73463db6fac68b26b24832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c91687ff80064ddf89abd709fe398488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw07bIXxnR1s",
        "outputId": "dde2b62d-641e-44ea-e41d-ca92ec03c220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace this with your own path where you want the code to be\n",
        "!cd /content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github"
      ],
      "metadata": {
        "id": "vtzqFhARnc5X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/chandar-lab/healthy-data-diet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIbHoVLCn-G9",
        "outputId": "04899770-1ff1-469f-9aa7-9c8c73d9abce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'healthy-data-diet'...\n",
            "remote: Enumerating objects: 936, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 936 (delta 60), reused 28 (delta 28), pack-reused 808\u001b[K\n",
            "Receiving objects: 100% (936/936), 15.07 MiB | 10.98 MiB/s, done.\n",
            "Resolving deltas: 100% (466/466), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github/healthy-data-diet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0UwsfAKoDs0",
        "outputId": "50557618-5b8c-4011-c338-a1b977ee4fae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github/healthy-data-diet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ1lcLEjoJB6",
        "outputId": "ab7ae500-2795-4feb-8250-675e1c584396"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.13.10-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.13.1+cu116)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (3.5.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (0.11.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert->-r requirements.txt (line 1)) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert->-r requirements.txt (line 1)) (2.25.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert->-r requirements.txt (line 1)) (2022.6.2)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.80-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 2)) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 2)) (23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 3)) (3.19.6)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 3)) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 3)) (4.5.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 3)) (5.4.8)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb->-r requirements.txt (line 3)) (1.4.4)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.16.0-py2.py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 6)) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 8)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.38.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 3)) (1.15.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert->-r requirements.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert->-r requirements.txt (line 1)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert->-r requirements.txt (line 1)) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting botocore<1.30.0,>=1.29.80\n",
            "  Downloading botocore-1.29.80-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: sklearn, pathtools\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=d4f9fd272267c692c398af9a10d4724e1460992d4c4500579ac408e615011a7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=a7e4a1590e4738f6319edc3178a461aa62f77844143b2d23a177a79caa516e10\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
            "Successfully built sklearn pathtools\n",
            "Installing collected packages: tokenizers, sklearn, pathtools, urllib3, smmap, setproctitle, jmespath, docker-pycreds, sentry-sdk, gitdb, botocore, s3transfer, huggingface-hub, GitPython, wandb, transformers, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed GitPython-3.1.31 boto3-1.26.80 botocore-1.29.80 docker-pycreds-0.4.0 gitdb-4.0.10 huggingface-hub-0.12.1 jmespath-1.0.1 pathtools-0.1.2 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 sentry-sdk-1.16.0 setproctitle-1.3.2 sklearn-0.0.post1 smmap-5.0.0 tokenizers-0.13.2 transformers-4.26.1 urllib3-1.26.14 wandb-0.13.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Downloading BERT and RoBERTa models\n",
        "\n",
        "from transformers import BertForSequenceClassification, RobertaForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
        "model.save_pretrained(\"./saved_models/cached_models/bert-base-cased\")\n",
        "\n",
        "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
        "model.save_pretrained(\"./saved_models/cached_models/roberta-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349,
          "referenced_widgets": [
            "b8266a43fc5f40d5a66b6d8b3c6f8a18",
            "a28f816d75314f8da27a4ea5d6758fc1",
            "9e1885f058b242a5a6b299b08fb1e3e8",
            "c8897b6ea00849a5ac3c549a0b383a09",
            "fb47fba6e7ac40c4ae065297d1b5977c",
            "1c1e326bbc4343b6bfc6a3304773804a",
            "f7351f517ab84832ab1d12930f53624a",
            "7bb6bc86e3ee4f37a10dcec75f128bb9",
            "bf8d4182250b4f499e03f03c4f3817a6",
            "340e8f67512a4133a3aa22d6257b86e7",
            "bff1f78a9f9a491389c8438ede5f497d",
            "18e695ff42c7497a90e78b7838c50d62",
            "082e2b3139f1463bb35c922a899195b9",
            "b03362380e0c4ad995fe34a51a589659",
            "51e36ec24a914401bf5d43526961d15f",
            "386a6cd59867470087bceef69c8fe462",
            "dd50f4c392e4415c9229c8d25912ef83",
            "a95aca8e202548c68f143fbcffeb0773",
            "27ae61fe79414bcc85208e6c8f774b37",
            "0cdd03d26f5d41eea1a6782ba43c88b4",
            "167e784283c84439af85429c65842993",
            "e90bb6b0168a497d82c8260eecc7bf5d",
            "3eb3cad001484041a03e22a026d2b912",
            "3e9387e72b07486f938a52e901de5463",
            "46f27664935c4ae99fce551356054b81",
            "19d733bc625f4761b0dc336d5e5356e4",
            "72d5ee53c6c94e00afeb3c9ef634c022",
            "9f88571f31d84ba8a12b047c9f0cf77c",
            "b20e66ef00814c8eb87afc5a0558f005",
            "cdbd3ab62ab34075bb616d191b139b09",
            "80affc73986b4d6697a0a261ce8e58e1",
            "24173ede048848a5b5e79986516b27fa",
            "1c66105e9fb4489f8858c3f9ac3c530d",
            "d290183ab127487184ab46dba813634a",
            "d82f65b5ad0b458ea3cf02b97086faaf",
            "0a5d163aae51484ea21c670082cd51a5",
            "a53d08c9bcd8418ea90158c373a04f4e",
            "66589e6f40b04c10a4cfee21f98a1f97",
            "573b251324364adbbfc9b6faf915b177",
            "36ecc61017eb40a59dce0e7b8d74410e",
            "8d79317411914ecb967ac5427a6ebe5c",
            "3d8eae7892ae47be972b9497d4d23cc8",
            "7cc0ab496e73463db6fac68b26b24832",
            "c91687ff80064ddf89abd709fe398488"
          ]
        },
        "id": "YOwo8MY6pWx5",
        "outputId": "3280ff94-563d-41e6-bfad-b2d4416ffa76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8266a43fc5f40d5a66b6d8b3c6f8a18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18e695ff42c7497a90e78b7838c50d62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3eb3cad001484041a03e22a026d2b912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d290183ab127487184ab46dba813634a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Experiment 1***: **Verifying that GE score reflects the importance of counterfactual examples**\n",
        "\n",
        "The following command is used to do debiasing using data augmentation for the Twitter dataset using a RoBERTa model and a seed of 3 using 75% of the counterfactual examples that are ranked according to the EL2N score:"
      ],
      "metadata": {
        "id": "QaiCEOwd6azb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --dataset Twitter --seed 1 --classifier_model bert-base-cased --CDA_examples_ranking GE --batch_size_biased_model 64 --num_epochs_importance_score 1 --num_epochs_biased_model 1 --batch_size_debiased_model 64 --num_epochs_debiased_model 1 --analyze_results True -- compute_importance_scores True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6tJrLwitV3B",
        "outputId": "246aaa38-0f5e-41e0-fc71-98f7208ce8a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-28 01:58:37.180244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-28 01:58:37.180344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-28 01:58:37.180362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "/content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github/healthy-data-diet/model/classifier.py:50: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  train_dataset, val_dataset, test_dataset = data_loader(\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 13525\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 212\n",
            "  Number of trainable parameters = 124647170\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "100% 211/212 [02:47<00:00,  1.27it/s]***** Running Evaluation *****\n",
            "  Num examples = 1691\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/27 [00:00<00:02, 10.50it/s]\u001b[A\n",
            " 15% 4/27 [00:00<00:03,  6.31it/s]\u001b[A\n",
            " 19% 5/27 [00:00<00:03,  5.86it/s]\u001b[A\n",
            " 22% 6/27 [00:01<00:03,  5.51it/s]\u001b[A\n",
            " 26% 7/27 [00:01<00:03,  5.42it/s]\u001b[A\n",
            " 30% 8/27 [00:01<00:03,  5.24it/s]\u001b[A\n",
            " 33% 9/27 [00:01<00:03,  5.12it/s]\u001b[A\n",
            " 37% 10/27 [00:01<00:03,  5.05it/s]\u001b[A\n",
            " 41% 11/27 [00:02<00:03,  4.96it/s]\u001b[A\n",
            " 44% 12/27 [00:02<00:02,  5.03it/s]\u001b[A\n",
            " 48% 13/27 [00:02<00:02,  5.00it/s]\u001b[A\n",
            " 52% 14/27 [00:02<00:02,  4.99it/s]\u001b[A\n",
            " 56% 15/27 [00:02<00:02,  4.95it/s]\u001b[A\n",
            " 59% 16/27 [00:03<00:02,  4.95it/s]\u001b[A\n",
            " 63% 17/27 [00:03<00:01,  5.00it/s]\u001b[A\n",
            " 67% 18/27 [00:03<00:01,  4.99it/s]\u001b[A\n",
            " 70% 19/27 [00:03<00:01,  4.97it/s]\u001b[A\n",
            " 74% 20/27 [00:03<00:01,  4.93it/s]\u001b[A\n",
            " 78% 21/27 [00:04<00:01,  4.94it/s]\u001b[A\n",
            " 81% 22/27 [00:04<00:01,  4.96it/s]\u001b[A\n",
            " 85% 23/27 [00:04<00:00,  4.97it/s]\u001b[A\n",
            " 89% 24/27 [00:04<00:00,  4.93it/s]\u001b[A\n",
            " 93% 25/27 [00:04<00:00,  4.94it/s]\u001b[A\n",
            " 96% 26/27 [00:05<00:00,  4.97it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5530878305435181, 'eval_runtime': 5.3285, 'eval_samples_per_second': 317.347, 'eval_steps_per_second': 5.067, 'epoch': 1.0}\n",
            "100% 211/212 [02:53<00:00,  1.27it/s]\n",
            "100% 27/27 [00:05<00:00,  4.99it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to saved_models//roberta-base/checkpoint-211\n",
            "Configuration saved in saved_models//roberta-base/checkpoint-211/config.json\n",
            "Model weights saved in saved_models//roberta-base/checkpoint-211/pytorch_model.bin\n",
            "100% 212/212 [03:00<00:00,  4.23s/it]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from saved_models//roberta-base/checkpoint-211 (score: 0.5530878305435181).\n",
            "{'train_runtime': 182.3025, 'train_samples_per_second': 74.19, 'train_steps_per_second': 1.163, 'train_loss': 0.5807925170322634, 'epoch': 1.0}\n",
            "100% 212/212 [03:01<00:00,  1.17it/s]\n",
            "main.py:358: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  train_dataset, val_dataset, test_dataset = data_loader(\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file ./saved_models/cached_models/roberta-base/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file ./saved_models/cached_models/roberta-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./saved_models/cached_models/roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 14877\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 233\n",
            "  Number of trainable parameters = 124647170\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "100% 232/233 [03:03<00:00,  1.25it/s]***** Running Evaluation *****\n",
            "  Num examples = 1691\n",
            "  Batch size = 64\n",
            "\n",
            "  0% 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 2/27 [00:00<00:02,  9.31it/s]\u001b[A\n",
            " 11% 3/27 [00:00<00:03,  7.35it/s]\u001b[A\n",
            " 15% 4/27 [00:00<00:03,  6.17it/s]\u001b[A\n",
            " 19% 5/27 [00:00<00:03,  5.74it/s]\u001b[A\n",
            " 22% 6/27 [00:01<00:03,  5.38it/s]\u001b[A\n",
            " 26% 7/27 [00:01<00:03,  5.23it/s]\u001b[A\n",
            " 30% 8/27 [00:01<00:03,  5.21it/s]\u001b[A\n",
            " 33% 9/27 [00:01<00:03,  5.10it/s]\u001b[A\n",
            " 37% 10/27 [00:01<00:03,  5.07it/s]\u001b[A\n",
            " 41% 11/27 [00:02<00:03,  5.00it/s]\u001b[A\n",
            " 44% 12/27 [00:02<00:03,  4.96it/s]\u001b[A\n",
            " 48% 13/27 [00:02<00:02,  4.96it/s]\u001b[A\n",
            " 52% 14/27 [00:02<00:02,  4.99it/s]\u001b[A\n",
            " 56% 15/27 [00:02<00:02,  4.98it/s]\u001b[A\n",
            " 59% 16/27 [00:03<00:02,  4.95it/s]\u001b[A\n",
            " 63% 17/27 [00:03<00:02,  4.94it/s]\u001b[A\n",
            " 67% 18/27 [00:03<00:01,  4.96it/s]\u001b[A\n",
            " 70% 19/27 [00:03<00:01,  4.98it/s]\u001b[A\n",
            " 74% 20/27 [00:03<00:01,  4.97it/s]\u001b[A\n",
            " 78% 21/27 [00:04<00:01,  4.91it/s]\u001b[A\n",
            " 81% 22/27 [00:04<00:01,  4.94it/s]\u001b[A\n",
            " 85% 23/27 [00:04<00:00,  5.00it/s]\u001b[A\n",
            " 89% 24/27 [00:04<00:00,  5.01it/s]\u001b[A\n",
            " 93% 25/27 [00:04<00:00,  4.97it/s]\u001b[A\n",
            " 96% 26/27 [00:05<00:00,  4.99it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5790863037109375, 'eval_runtime': 5.3324, 'eval_samples_per_second': 317.116, 'eval_steps_per_second': 5.063, 'epoch': 1.0}\n",
            "100% 232/233 [03:09<00:00,  1.25it/s]\n",
            "100% 27/27 [00:05<00:00,  4.98it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to saved_models//roberta-base/checkpoint-232\n",
            "Configuration saved in saved_models//roberta-base/checkpoint-232/config.json\n",
            "Model weights saved in saved_models//roberta-base/checkpoint-232/pytorch_model.bin\n",
            "100% 233/233 [03:15<00:00,  4.08s/it]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from saved_models//roberta-base/checkpoint-232 (score: 0.5790863037109375).\n",
            "{'train_runtime': 196.1958, 'train_samples_per_second': 75.827, 'train_steps_per_second': 1.188, 'train_loss': 0.6269807610900617, 'epoch': 1.0}\n",
            "100% 233/233 [03:16<00:00,  1.19it/s]\n",
            "/content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github/healthy-data-diet/model/metrics.py:79: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  ) = data_loader(\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file ./saved_models/cached_models/roberta-base/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file ./saved_models/cached_models/roberta-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./saved_models/cached_models/roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "/content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github/healthy-data-diet/analysis.py:79: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  train_dataset, val_dataset, test_dataset = data_loader(\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file ./saved_models/cached_models/roberta-base/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file ./saved_models/cached_models/roberta-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./saved_models/cached_models/roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "loading configuration file ./saved_models/cached_models/roberta-base/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file ./saved_models/cached_models/roberta-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./saved_models/cached_models/roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file ./saved_models/cached_models/roberta-base/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file ./saved_models/cached_models/roberta-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./saved_models/cached_models/roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "loading configuration file ./saved_models/cached_models/roberta-base/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file ./saved_models/cached_models/roberta-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./saved_models/cached_models/roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Demographic parity after bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    Demographic parity before bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  IPTTS_gender_bias AUC after bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: IPTTS_gender_bias AUC before bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  IPTTS_social_bias AUC after bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: IPTTS_social_bias AUC before bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   eval/loss ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                eval/runtime ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     eval/samples_per_second █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       eval/steps_per_second █▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               test AUC after bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test AUC before bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 train/epoch ▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                           train/global_step ▁▁███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            train/total_flos ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            train/train_loss ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                         train/train_runtime ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/train_samples_per_second ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                train/train_steps_per_second ▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         validation AUC after bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        validation AUC before bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        validation bias after bias reduction ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     Demographic parity after bias reduction 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    Demographic parity before bias reduction 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  IPTTS_gender_bias AUC after bias reduction 0.49094\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: IPTTS_gender_bias AUC before bias reduction 0.43954\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  IPTTS_social_bias AUC after bias reduction 0.488\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: IPTTS_social_bias AUC before bias reduction 0.39077\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                   eval/loss 0.57909\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                eval/runtime 5.3324\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     eval/samples_per_second 317.116\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                       eval/steps_per_second 5.063\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               test AUC after bias reduction 0.51959\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              test AUC before bias reduction 0.49094\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                 train/epoch 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                           train/global_step 233\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            train/total_flos 565739130124440.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                            train/train_loss 0.62698\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                         train/train_runtime 196.1958\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/train_samples_per_second 75.827\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                train/train_steps_per_second 1.188\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         validation AUC after bias reduction 0.52299\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        validation AUC before bias reduction 0.49659\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        validation bias after bias reduction 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github/healthy-data-diet/wandb/offline-run-20230228_015848-flcn2ped\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20230228_015848-flcn2ped/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Experiment 2***: **Finding the best trade-off between fairness and performance**\n",
        "\n",
        "The following command is used to do debiasing with 30% of the factual examples and 20% of the counterfactual examples using the proposed healthy random ranking for the Jigsaw dataset with RoBERTa model and a seed of 5:"
      ],
      "metadata": {
        "id": "Nj5Sjrmb7B15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --batch_size_biased_model 32 --seed 5 --num_epochs_biased_model 10 --dataset Jigsaw --batch_size_debiased_model 32 --method data_diet --num_epochs_debiased_model 10 --classifier_model roberta-base --max_length 40 --analyze_results True --data_diet_factual_ratio 0.3 --data_diet_counterfactual_ratio 0.2 --data_diet_examples_ranking healthy_random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lm9Sm9yvi9z",
        "outputId": "50caeaab-193d-44c7-c3ea-c48b2e08c285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-28 02:49:33.227822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-28 02:49:33.227990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-02-28 02:49:33.228014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "/content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github/healthy-data-diet/model/classifier.py:50: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  train_dataset, val_dataset, test_dataset = data_loader(\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 13525\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 423\n",
            "  Number of trainable parameters = 124647170\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "100% 422/423 [01:45<00:00,  4.01it/s]***** Running Evaluation *****\n",
            "  Num examples = 1691\n",
            "  Batch size = 32\n",
            "\n",
            "  0% 0/53 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 3/53 [00:00<00:02, 23.95it/s]\u001b[A\n",
            " 11% 6/53 [00:00<00:02, 17.34it/s]\u001b[A\n",
            " 15% 8/53 [00:00<00:02, 15.94it/s]\u001b[A\n",
            " 19% 10/53 [00:00<00:02, 15.11it/s]\u001b[A\n",
            " 23% 12/53 [00:00<00:02, 15.10it/s]\u001b[A\n",
            " 26% 14/53 [00:00<00:02, 14.52it/s]\u001b[A\n",
            " 30% 16/53 [00:01<00:02, 14.60it/s]\u001b[A\n",
            " 34% 18/53 [00:01<00:02, 14.62it/s]\u001b[A\n",
            " 38% 20/53 [00:01<00:02, 14.68it/s]\u001b[A\n",
            " 42% 22/53 [00:01<00:02, 14.57it/s]\u001b[A\n",
            " 45% 24/53 [00:01<00:02, 14.28it/s]\u001b[A\n",
            " 49% 26/53 [00:01<00:01, 14.15it/s]\u001b[A\n",
            " 53% 28/53 [00:01<00:01, 13.98it/s]\u001b[A\n",
            " 57% 30/53 [00:02<00:01, 14.19it/s]\u001b[A\n",
            " 60% 32/53 [00:02<00:01, 14.32it/s]\u001b[A\n",
            " 64% 34/53 [00:02<00:01, 14.27it/s]\u001b[A\n",
            " 68% 36/53 [00:02<00:01, 14.35it/s]\u001b[A\n",
            " 72% 38/53 [00:02<00:01, 14.13it/s]\u001b[A\n",
            " 75% 40/53 [00:02<00:00, 14.14it/s]\u001b[A\n",
            " 79% 42/53 [00:02<00:00, 14.11it/s]\u001b[A\n",
            " 83% 44/53 [00:03<00:00, 14.13it/s]\u001b[A\n",
            " 87% 46/53 [00:03<00:00, 14.32it/s]\u001b[A\n",
            " 91% 48/53 [00:03<00:00, 14.27it/s]\u001b[A\n",
            " 94% 50/53 [00:03<00:00, 14.41it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5202724933624268, 'eval_runtime': 3.7161, 'eval_samples_per_second': 455.041, 'eval_steps_per_second': 14.262, 'epoch': 1.0}\n",
            "100% 422/423 [01:49<00:00,  4.01it/s]\n",
            "100% 53/53 [00:03<00:00, 14.22it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to saved_models//roberta-base/checkpoint-422\n",
            "Configuration saved in saved_models//roberta-base/checkpoint-422/config.json\n",
            "Model weights saved in saved_models//roberta-base/checkpoint-422/pytorch_model.bin\n",
            "100% 423/423 [01:55<00:00,  3.15s/it]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from saved_models//roberta-base/checkpoint-422 (score: 0.5202724933624268).\n",
            "{'train_runtime': 116.4903, 'train_samples_per_second': 116.104, 'train_steps_per_second': 3.631, 'train_loss': 0.538513652539986, 'epoch': 1.0}\n",
            "100% 423/423 [01:56<00:00,  3.63it/s]\n",
            "main.py:358: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  train_dataset, val_dataset, test_dataset = data_loader(\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file ./saved_models/cached_models/roberta-base/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file ./saved_models/cached_models/roberta-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./saved_models/cached_models/roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 6762\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 212\n",
            "  Number of trainable parameters = 124647170\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "100% 211/212 [00:52<00:00,  3.99it/s]***** Running Evaluation *****\n",
            "  Num examples = 1691\n",
            "  Batch size = 32\n",
            "\n",
            "  0% 0/53 [00:00<?, ?it/s]\u001b[A\n",
            "  6% 3/53 [00:00<00:02, 22.27it/s]\u001b[A\n",
            " 11% 6/53 [00:00<00:02, 16.55it/s]\u001b[A\n",
            " 15% 8/53 [00:00<00:02, 15.37it/s]\u001b[A\n",
            " 19% 10/53 [00:00<00:02, 14.58it/s]\u001b[A\n",
            " 23% 12/53 [00:00<00:02, 14.25it/s]\u001b[A\n",
            " 26% 14/53 [00:00<00:02, 14.03it/s]\u001b[A\n",
            " 30% 16/53 [00:01<00:02, 14.11it/s]\u001b[A\n",
            " 34% 18/53 [00:01<00:02, 14.08it/s]\u001b[A\n",
            " 38% 20/53 [00:01<00:02, 13.95it/s]\u001b[A\n",
            " 42% 22/53 [00:01<00:02, 14.00it/s]\u001b[A\n",
            " 45% 24/53 [00:01<00:02, 13.81it/s]\u001b[A\n",
            " 49% 26/53 [00:01<00:01, 13.72it/s]\u001b[A\n",
            " 53% 28/53 [00:01<00:01, 13.71it/s]\u001b[A\n",
            " 57% 30/53 [00:02<00:01, 13.72it/s]\u001b[A\n",
            " 60% 32/53 [00:02<00:01, 13.94it/s]\u001b[A\n",
            " 64% 34/53 [00:02<00:01, 13.95it/s]\u001b[A\n",
            " 68% 36/53 [00:02<00:01, 13.91it/s]\u001b[A\n",
            " 72% 38/53 [00:02<00:01, 13.74it/s]\u001b[A\n",
            " 75% 40/53 [00:02<00:00, 13.71it/s]\u001b[A\n",
            " 79% 42/53 [00:02<00:00, 13.80it/s]\u001b[A\n",
            " 83% 44/53 [00:03<00:00, 13.83it/s]\u001b[A\n",
            " 87% 46/53 [00:03<00:00, 13.83it/s]\u001b[A\n",
            " 91% 48/53 [00:03<00:00, 13.92it/s]\u001b[A\n",
            " 94% 50/53 [00:03<00:00, 13.86it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5871299505233765, 'eval_runtime': 3.8322, 'eval_samples_per_second': 441.265, 'eval_steps_per_second': 13.83, 'epoch': 1.0}\n",
            "100% 211/212 [00:56<00:00,  3.99it/s]\n",
            "100% 53/53 [00:03<00:00, 13.79it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to saved_models//roberta-base/checkpoint-211\n",
            "Configuration saved in saved_models//roberta-base/checkpoint-211/config.json\n",
            "Model weights saved in saved_models//roberta-base/checkpoint-211/pytorch_model.bin\n",
            "100% 212/212 [01:03<00:00,  3.29s/it]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from saved_models//roberta-base/checkpoint-211 (score: 0.5871299505233765).\n",
            "{'train_runtime': 64.3697, 'train_samples_per_second': 105.049, 'train_steps_per_second': 3.293, 'train_loss': 0.615807371319465, 'epoch': 1.0}\n",
            "100% 212/212 [01:04<00:00,  3.30it/s]\n",
            "/content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github/healthy-data-diet/model/metrics.py:79: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  ) = data_loader(\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading configuration file ./saved_models/cached_models/roberta-base/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file ./saved_models/cached_models/roberta-base/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./saved_models/cached_models/roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "/content/drive/MyDrive/PhD/Mila/MSR/Healthy_data_diet/github/healthy-data-diet/analysis.py:79: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  train_dataset, val_dataset, test_dataset = data_loader(\n"
          ]
        }
      ]
    }
  ]
}